from flask import Flask, request, jsonify, send_from_directory, send_file, render_template, abort, url_for
from werkzeug.utils import safe_join
import os
from openai import OpenAI
from dotenv import load_dotenv
import tempfile
from datetime import datetime

# API í‚¤ ê°€ì ¸ì˜¤ê¸°(=ë¡œë“œ)
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")
app = Flask(__name__)

# ì—…ë¡œë“œ í´ë” ê²½ë¡œ
UPLOAD_FOLDER = "uploads"
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

@app.route('/')
@app.route('/speech.html')
def serve_html():
    return render_template('speech.html')

@app.route("/uploads/<filename>")
def get_uploaded_file(filename):
    return send_from_directory(UPLOAD_FOLDER, filename)

# (ë§ˆì´í¬ ì¼œì„œ) í…ìŠ¤íŠ¸ ë°›ì•„ì˜¤ê¸° -> STT ê¸°ëŠ¥
@app.route("/speak", methods=["POST"])
def speak():
    text = request.json.get("text")
    if not text:
        return jsonify({"error": "text field is required"}), 400

    try:
        client = OpenAI(api_key=openai_api_key)
        response = client.audio.speech.create(
            model="tts-1-hd",       # âœ… ì˜¬ë°”ë¥¸ TTS ëª¨ë¸
            voice="shimmer",        # âœ… ìŒì„± ìŠ¤íƒ€ì¼ shimmer
            input=text
        )
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
        temp_file.write(response.content)
        temp_file.close()
        return send_file(temp_file.name, mimetype="audio/mpeg")
    except Exception as e:
        return jsonify({"error": str(e)}), 500

# transcript ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬ (ì„ì‹œ ë©”ëª¨ë¦¬ìš© â€“ í”„ë¡œë•ì…˜ì—ì„  DBë‚˜ íŒŒì¼ ê¶Œì¥)
transcript_store = {}

@app.route("/upload", methods=["POST"])
def upload_audio():
    # 1. ì‚¬ìš©ìê°€ ë³´ë‚¸ ì˜¤ë””ì˜¤ íŒŒì¼ê³¼ STT í…ìŠ¤íŠ¸ ë°›ê¸°
    audio = request.files.get("audio")
    transcript = request.form.get("transcript", "")

    # ì›ë˜ ë°œìŒ(raw transcript)ë¥¼ ê·¸ëŒ€ë¡œ ìœ ì§€
    raw_transcript = transcript
    if audio is None:
        return jsonify({"error": "No audio file provided"}), 400

    # 2. ì˜¤ë””ì˜¤ íŒŒì¼ì„ ê³ ìœ  íŒŒì¼ëª…(ì‹œê°„)ìœ¼ë¡œ ì„¤ì •
    timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
    filename = f"recording_{timestamp}.webm"
    
    # 3. íŒŒì¼ ì €ì¥
    save_path = os.path.join(UPLOAD_FOLDER, filename)
    audio.save(save_path)
    
    # 4. (ì‹œê°„ì— ë”°ë¼ ì €ì¥í•œ) íŒŒì¼ì— ì œëª©ìœ¼ë¡œ 'ë°œìŒí•œ ë¬¸ì¥'ì„ ëŒ€ì…
    txt_path = os.path.join(UPLOAD_FOLDER, f"recording_{timestamp}.txt")
    with open(txt_path, "w", encoding="utf-8") as f:
        f.write(raw_transcript)

    # 5. GPT í˜¸ì¶œí•´ì„œ êµì • (ì›ë³¸ ë°œìŒ ê·¸ëŒ€ë¡œ ì „ë‹¬)
    answer = generate_correct_sentence(raw_transcript)

    # 6. ê²°ê³¼ ë°˜í™˜ - ì›ë³¸ ë°œìŒê³¼ êµì •ëœ ë¬¸ì¥ ëª¨ë‘ ë°˜í™˜
    return jsonify({
        "raw_transcript": raw_transcript,  # ì›ë³¸ ë°œìŒ ê·¸ëŒ€ë¡œ
        "answer": answer,                   # êµì •ëœ ë¬¸ì¥
        "filename": filename
    })     
    
    
#ì €ì¥ëœ íŒŒì¼ ëª©ë¡ì„ ë°˜í™˜í•˜ëŠ” API ì¶”ê°€
@app.route("/recordings")
def list_recordings():
    files = sorted(f for f in os.listdir(UPLOAD_FOLDER) if f.endswith(".webm"))
   
    #<ì €ì¥ëœ ë¬¸ì¥>ì— í•œê¸€ ì œëª©ìœ¼ë¡œ í‘œì‹œ
    result = []
    for f in files:
        transcript_path = os.path.join(UPLOAD_FOLDER, f.replace(".webm", ".txt"))
        if os.path.exists(transcript_path):
            with open(transcript_path, "r", encoding="utf-8") as tfile:
                transcript = tfile.read().strip()
        else:
            transcript = "(ë‚´ìš© ì—†ìŒ)"
        preview = transcript[:15] + "..." if len(transcript) > 15 else transcript
        result.append({ "filename": f, "preview": preview })

    return jsonify(result)   

@app.route("/audio/<filename>")
def get_specific_audio(filename):
    file_path = safe_join(UPLOAD_FOLDER, filename)
    if not os.path.exists(file_path):
        abort(404)
    return send_from_directory(UPLOAD_FOLDER, filename)

def generate_correct_sentence(user_text: str) -> str:

    """
    OpenAI GPT ëª¨ë¸ì„ ì‚¬ìš©í•´
    ì‚¬ìš©ì ë°œí™”ë¬¸ì¥ì„ ìì—°ìŠ¤ëŸ½ê³  ì˜¬ë°”ë¥¸ í•œêµ­ì–´ ë¬¸ì¥ìœ¼ë¡œ êµì •í•¨
    """
    prompt = (
        f"ì‚¬ìš©ìì˜ ì‹¤ì œ ë°œìŒ: \"{user_text}\"\n"
        "ì´ ë°œìŒì„ ì˜¬ë°”ë¥¸ í•œêµ­ì–´ ë¬¸ì¥ìœ¼ë¡œ êµì •í•´ì£¼ì„¸ìš”. ì˜ˆë¥¼ ë“¤ì–´ 'ê±°ê¸°ë§ˆ ë¨¹ê³  ì‹œë”°'ëŠ” 'ê³ êµ¬ë§ˆ ë¨¹ê³  ì‹¶ë‹¤'ë¡œ êµì •í•´ì•¼ í•©ë‹ˆë‹¤.\n"
        "ë°œìŒì´ ì •í™•í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì‚¬ìš©ìê°€ ì˜ë„í–ˆì„ ê°€ëŠ¥ì„±ì´ ë†’ì€ ë¬¸ì¥ë“¤ë¡œ êµì •í•œ ë¬¸ì¥ ì„¸ ê°œë¥¼ ì£¼ì„¸ìš”."
    )

    try:
        client = OpenAI(api_key=openai_api_key)
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": "ë„ˆëŠ” í•œêµ­ì–´ ë°œìŒ êµì •ì„ ë•ëŠ” êµì‚¬ì•¼. ì‚¬ìš©ìì˜ ë¶€ì •í™•í•œ ë°œìŒì„ ì˜¬ë°”ë¥¸ í•œêµ­ì–´ ë¬¸ì¥ìœ¼ë¡œ êµì •í•´ì¤˜."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            max_tokens=100,
            temperature=0.3,
        )
        corrected_sentence = response.choices[0].message.content.strip()
        print(f"GPT êµì • ê²°ê³¼: {corrected_sentence}")
        return corrected_sentence
    except Exception as e:
        print(f"GPT í˜¸ì¶œ ì—ëŸ¬: {e}")
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ë¬¸ì¥ êµì •ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."

# <ì €ì¥ëœ ë¬¸ì¥>ì—ì„œ ë¬¸ì¥ ì‚­ì œí•˜ê¸° ê¸°ëŠ¥
@app.route("/delete/<filename>", methods=["DELETE"])
def delete_recording(filename):
    filepath = os.path.join(UPLOAD_FOLDER, filename)
    try:
        os.remove(filepath)
        transcript_store.pop(filename, None)  # ğŸ”¹ í•¨ê»˜ ì‚­ì œ
        return jsonify({"status": "deleted"}), 200
    except Exception as e:
        return jsonify({"error": str(e)}), 500
    
if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000, debug=True)
